{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Data_Cleaning_TorontoAfterTheFirstWave",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYcAGJR0Ja16"
      },
      "source": [
        "LIST OF PROBLEMS ENCOUNTERED\n",
        "1. need to first only include rows in original xlsx file that were data from jan 2020 to apr 2021\n",
        "2. get rid of end rows where xlsx calculations are done (bc they don't come from from merging the dfs, they come from editing the output xlsx file)\n",
        "3. get rid of 1st col (Column1) bc it wasn't in initial df (first listings.csv) that was used to initialize result variable.\n",
        "4. convert the old df to csv with utf-8 formatting (bc the original xlsx can take utf-8 chars)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfNb_i4aYoMY"
      },
      "source": [
        "# Airbnb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vhz6WBFdYxba"
      },
      "source": [
        "1) Calculate changes in number of listings using datasets from January 2020 to Present(January 2021). Datasets obtained from http://insideairbnb.com/get-the-data.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCMnFPfpI1KI",
        "outputId": "c8ee8926-2ae1-4dcd-fc63-768b34e3ab3d"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "MAL = 0 #average number of listings per month over the past year\n",
        "\n",
        "def calculate_off_new(df, df2):\n",
        "  merged = df.merge(df2[['id', 'price']],\n",
        "                  on='id', \n",
        "                  how='left')\n",
        "\n",
        "  isNaN = merged.price_y != merged.price_y\n",
        "  isOff = merged[isNaN]\n",
        "  print('#Off:')\n",
        "  print(len(isOff.index))\n",
        "  print('#New:')\n",
        "  print(len(df2.index) + len(isOff.index) - len(df.index))\n",
        "  print('#Total Change:')\n",
        "  print(len(df2.index) - len(df.index))\n",
        "\n",
        "################################ COMPARE MAR-APR 2021\n",
        "df = pd.read_csv(\"inputs/apr2021_listings.csv\")\n",
        "df2 = pd.read_csv(\"inputs/may2021_listings.csv\")\n",
        "calculate_off_new(df, df2)\n",
        "\n",
        "######## WHEN STARTING ANEW, SET FIRST DF TO BE RESULT\n",
        "result = pd.read_csv(\"old df - AirbnbTO_2021.csv\", encoding='utf-8')\n",
        "# result = df\n",
        "\n",
        "# add monthly price changes\n",
        "result = result.merge(df2[['id', 'price']], on='id')\n",
        "print(result.shape)\n",
        "\n",
        "################################ COMPARE FEB-MAR 2020\n",
        "df = df2\n",
        "df2 = pd.read_csv(\"inputs/jun2021_listings.csv\")\n",
        "result = result.merge(df2[['id', 'price']], on='id')\n",
        "\n",
        "df = df2\n",
        "df2 = pd.read_csv(\"inputs/jul2021_listings.csv\")\n",
        "result = result.merge(df2[['id', 'price']], on='id')\n",
        "\n",
        "df = df2\n",
        "df2 = pd.read_csv(\"inputs/aug2021_listings.csv\")\n",
        "result = result.merge(df2[['id', 'price']], on='id')\n",
        "\n",
        "result.to_excel('outputs/04 - JAN-AUG_AirbnbTO.xlsx')\n",
        "print(\"DONE!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Off:\n",
            "754\n",
            "#New:\n",
            "747\n",
            "#Total Change:\n",
            "-7\n",
            "(3249, 32)\n",
            "DONE!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "3o5E3TBT_Tyw",
        "outputId": "05dec455-56f7-49ed-f8ee-0328e71a1b15"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "MAL = 0 #average number of listings per month over the past year\n",
        "\n",
        "def calculate_off_new(df, df2):\n",
        "  merged = df.merge(df2[['id', 'price']],\n",
        "                  on='id', \n",
        "                  how='left')\n",
        "\n",
        "  isNaN = merged.price_y != merged.price_y\n",
        "  isOff = merged[isNaN]\n",
        "  print('#Off:')\n",
        "  print(len(isOff.index))\n",
        "  print('#New:')\n",
        "  print(len(df2.index) + len(isOff.index) - len(df.index))\n",
        "  print('#Total Change:')\n",
        "  print(len(df2.index) - len(df.index))\n",
        "\n",
        "################################ COMPARE JAN-FEB 2020\n",
        "df = pd.read_csv(\"listings.csv\")\n",
        "print('-----------------> JAN-FEB 2020 changes in listings:')\n",
        "df2 = pd.read_csv(\"listings_feb.csv\")\n",
        "calculate_off_new(df, df2)\n",
        "# add monthly price changes\n",
        "result = df\n",
        "result = result.merge(df2[['id', 'price']], on='id')\n",
        "print(result.shape)\n",
        "MAL = len(df2.index) + len(df.index)\n",
        "\n",
        "################################ COMPARE FEB-MAR 2020\n",
        "df = pd.read_csv(\"listings_feb.csv\")\n",
        "print('-----------------> FEB-MAR 2020 changes in listings:')\n",
        "df2 = pd.read_csv(\"listings_mar.csv\")\n",
        "calculate_off_new(df, df2)\n",
        "# add monthly price changes\n",
        "result = result.merge(df2[['id', 'price']], on='id')\n",
        "print(result.shape)\n",
        "MAL = MAL + len(df2.index)\n",
        "\n",
        "################################ COMPARE MAR-APR 2020\n",
        "df = pd.read_csv(\"listings_mar.csv\")\n",
        "print('-----------------> MAR-APR 2020 changes in listings:')\n",
        "df2 = pd.read_csv(\"listings_apr.csv\")\n",
        "calculate_off_new(df, df2)\n",
        "# add monthly price changes\n",
        "result = result.merge(df2[['id', 'price']], on='id')\n",
        "print(result.shape)\n",
        "MAL = MAL + len(df2.index)\n",
        "\n",
        "################################ COMPARE APR-MAY 2020\n",
        "df = pd.read_csv(\"listings_apr.csv\")\n",
        "print('-----------------> APR-MAY 2020 changes in listings:')\n",
        "df2 = pd.read_csv(\"listings_may.csv\")\n",
        "calculate_off_new(df, df2)\n",
        "# add monthly price changes\n",
        "result = result.merge(df2[['id', 'price']], on='id')\n",
        "print(result.shape)\n",
        "MAL = MAL + len(df2.index)\n",
        "\n",
        "################################ COMPARE MAY-JUN 2020\n",
        "df = pd.read_csv(\"listings_may.csv\")\n",
        "print('-----------------> MAY-JUN 2020 changes in listings:')\n",
        "df2 = pd.read_csv(\"listings_jun.csv\")\n",
        "calculate_off_new(df, df2)\n",
        "# add monthly price changes\n",
        "result = result.merge(df2[['id', 'price']], on='id')\n",
        "print(result.shape)\n",
        "MAL = MAL + len(df2.index)\n",
        "\n",
        "################################ COMPARE JUN-JUL 2020\n",
        "df = pd.read_csv(\"listings_jun.csv\")\n",
        "print('-----------------> JUN-JUL 2020 changes in listings:')\n",
        "df2 = pd.read_csv(\"listings_jul.csv\")\n",
        "calculate_off_new(df, df2)\n",
        "# add monthly price changes\n",
        "result = result.merge(df2[['id', 'price']], on='id')\n",
        "print(result.shape)\n",
        "MAL = MAL + len(df2.index)\n",
        "\n",
        "################################ COMPARE JUL-AUG 2020\n",
        "df = pd.read_csv(\"listings_jul.csv\")\n",
        "print('-----------------> JUL-AUG 2020 changes in listings:')\n",
        "df2 = pd.read_csv(\"listings_aug.csv\")\n",
        "calculate_off_new(df, df2)\n",
        "# add monthly price changes\n",
        "result = result.merge(df2[['id', 'price']], on='id')\n",
        "print(result.shape)\n",
        "MAL = MAL + len(df2.index)\n",
        "\n",
        "################################ COMPARE AUG-SEP 2020\n",
        "df = pd.read_csv(\"listings_aug.csv\")\n",
        "print('-----------------> AUG-SEP 2020 changes in listings:')\n",
        "df2 = pd.read_csv(\"listings_sep.csv\")\n",
        "calculate_off_new(df, df2)\n",
        "# add monthly price changes\n",
        "result = result.merge(df2[['id', 'price']], on='id')\n",
        "print(result.shape)\n",
        "MAL = MAL + len(df2.index)\n",
        "\n",
        "################################ COMPARE SEP-OCT 2020\n",
        "df = pd.read_csv(\"listings_sep.csv\")\n",
        "print('-----------------> SEP-OCT 2020 changes in listings:')\n",
        "df2 = pd.read_csv(\"listings_oct.csv\")\n",
        "calculate_off_new(df, df2)\n",
        "# add monthly price changes\n",
        "result = result.merge(df2[['id', 'price']], on='id')\n",
        "print(result.shape)\n",
        "MAL = MAL + len(df2.index)\n",
        "\n",
        "################################ COMPARE OCT-NOV 2020\n",
        "df = pd.read_csv(\"listings_oct.csv\")\n",
        "print('-----------------> OCT-NOV 2020 changes in listings:')\n",
        "df2 = pd.read_csv(\"listings_nov.csv\")\n",
        "calculate_off_new(df, df2)\n",
        "# add monthly price changes\n",
        "result = result.merge(df2[['id', 'price']], on='id')\n",
        "print(result.shape)\n",
        "MAL = MAL + len(df2.index)\n",
        "\n",
        "################################ COMPARE NOV-DEC 2020\n",
        "df = pd.read_csv(\"listings_nov.csv\")\n",
        "print('-----------------> NOV-DEC 2020 changes in listings:')\n",
        "df2 = pd.read_csv(\"listings_dec.csv\")\n",
        "calculate_off_new(df, df2)\n",
        "# add monthly price changes\n",
        "result = result.merge(df2[['id', 'price']], on='id')\n",
        "print(result.shape)\n",
        "MAL = MAL + len(df2.index)\n",
        "\n",
        "################################ COMPARE DEC-JAN 2021\n",
        "df = pd.read_csv(\"listings_dec.csv\")\n",
        "print('-----------------> DEC-JAN 2021 changes in listings:')\n",
        "df2 = pd.read_csv(\"listings_jan.csv\")\n",
        "calculate_off_new(df, df2)\n",
        "# add monthly price changes\n",
        "result = result.merge(df2[['id', 'price']], on='id')\n",
        "print(result.shape)\n",
        "MAL = MAL + len(df2.index)\n",
        "\n",
        "################################ COMPARE JAN-FEB 2021\n",
        "df = pd.read_csv(\"listings_jan.csv\")\n",
        "print('-----------------> JAN-FEB 2021 changes in listings:')\n",
        "df2 = pd.read_csv(\"feb_2021.csv\")\n",
        "calculate_off_new(df, df2)\n",
        "# add monthly price changes\n",
        "result = result.merge(df2[['id', 'price']], on='id')\n",
        "print(result.shape)\n",
        "MAL = MAL + len(df2.index)\n",
        "\n",
        "################################ COMPARE FEB-MAR 2021\n",
        "df = pd.read_csv(\"feb_2021.csv\")\n",
        "print('-----------------> FEB-MAR 2021 changes in listings:')\n",
        "df2 = pd.read_csv(\"mar_2021.csv\")\n",
        "calculate_off_new(df, df2)\n",
        "# add monthly price changes\n",
        "result = result.merge(df2[['id', 'price']], on='id')\n",
        "print(result.shape)\n",
        "MAL = MAL + len(df2.index)\n",
        "\n",
        "################################ COMPARE MAR-APR 2021\n",
        "df = pd.read_csv(\"mar_2021.csv\")\n",
        "print('-----------------> FEB-MAR 2021 changes in listings:')\n",
        "df2 = pd.read_csv(\"apr_2021.csv\")\n",
        "calculate_off_new(df, df2)\n",
        "# add monthly price changes\n",
        "result = result.merge(df2[['id', 'price']], on='id')\n",
        "print(result.shape)\n",
        "MAL = MAL + len(df2.index)\n",
        "\n",
        "print('-----------------> BASELINE (average monthly active listings):')\n",
        "print(MAL/16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-f607b81dd227>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m################################ COMPARE JAN-FEB 2020\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"listings.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-----------------> JAN-FEB 2020 changes in listings:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"listings_feb.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'listings.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJg0wtwYTZZd"
      },
      "source": [
        "result.to_excel('AirbnbTO.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peP1T-nFZM10"
      },
      "source": [
        "2) Calculate average prices and average number of listings by room type and by neighbourhood."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQitDmEaNsGx"
      },
      "source": [
        "#calculate average price by neighbourhoods and by airbnb type\n",
        "import pandas as pd\n",
        "\n",
        "result = pd.DataFrame(columns=['room_type','month','neighbourhood','count','monthly_average'])\n",
        "\n",
        "def monthly_average_by_neigh(result, df, room, month):\n",
        "  price_by_neigh_type = df[['neighbourhood', 'price']].groupby(['neighbourhood']).size().reset_index(name='count')\n",
        "  price_by_neigh_type['monthly_average'] = df['price'].groupby(df['neighbourhood']).transform('mean')\n",
        "  price_by_neigh_type.insert(0, 'month', month)\n",
        "  price_by_neigh_type.insert(0, 'room_type', room)\n",
        "  result = pd.concat([result, price_by_neigh_type])\n",
        "  print(result.shape)\n",
        "  return result\n",
        "\n",
        "def monthly_average_by_room_type(result, df, month):\n",
        "  isHotel = df['room_type'] == 'Hotel room'\n",
        "  result = monthly_average_by_neigh(result, df[isHotel],'Hotel Room', month)\n",
        "  isPrivate = df['room_type'] == 'Private room'\n",
        "  result = monthly_average_by_neigh(result, df[isPrivate],'Private Room', month)\n",
        "  isShared = df['room_type'] == 'Shared room'\n",
        "  result = monthly_average_by_neigh(result, df[isShared],'Shared Room', month)\n",
        "  isEntire = df['room_type'] == 'Entire home/apt'\n",
        "  result = monthly_average_by_neigh(result, df[isEntire], 'Entire Home', month)\n",
        "  return result\n",
        "\n",
        "df = pd.read_csv(\"listings.csv\")\n",
        "result = monthly_average_by_room_type(result, df, 'January, 2020')\n",
        "df = pd.read_csv(\"listings_feb.csv\")\n",
        "result = monthly_average_by_room_type(result, df, 'February, 2020')\n",
        "df = pd.read_csv(\"listings_mar.csv\")\n",
        "result = monthly_average_by_room_type(result, df, 'March, 2020')\n",
        "df = pd.read_csv(\"listings_apr.csv\")\n",
        "result = monthly_average_by_room_type(result, df, 'April, 2020')\n",
        "df = pd.read_csv(\"listings_may.csv\")\n",
        "result = monthly_average_by_room_type(result, df, 'May, 2020')\n",
        "df = pd.read_csv(\"listings_jun.csv\")\n",
        "result = monthly_average_by_room_type(result, df, 'June, 2020')\n",
        "df = pd.read_csv(\"listings_jul.csv\")\n",
        "result = monthly_average_by_room_type(result, df, 'July, 2020')\n",
        "df = pd.read_csv(\"listings_aug.csv\")\n",
        "result = monthly_average_by_room_type(result, df, 'August, 2020')\n",
        "df = pd.read_csv(\"listings_sep.csv\")\n",
        "result = monthly_average_by_room_type(result, df, 'September, 2020')\n",
        "df = pd.read_csv(\"listings_oct.csv\")\n",
        "result = monthly_average_by_room_type(result, df, 'October, 2020')\n",
        "df = pd.read_csv(\"listings_nov.csv\")\n",
        "result = monthly_average_by_room_type(result, df, 'November, 2020')\n",
        "df = pd.read_csv(\"listings_dec.csv\")\n",
        "result = monthly_average_by_room_type(result, df, 'December, 2020')\n",
        "df = pd.read_csv(\"listings_jan.csv\")\n",
        "result = monthly_average_by_room_type(result, df, 'January, 2021')\n",
        "df = pd.read_csv(\"feb_2021.csv\")\n",
        "result = monthly_average_by_room_type(result, df, 'February, 2021')\n",
        "df = pd.read_csv(\"mar_2021.csv\")\n",
        "result = monthly_average_by_room_type(result, df, 'March, 2021')\n",
        "df = pd.read_csv(\"apr_2021.csv\")\n",
        "result = monthly_average_by_room_type(result, df, 'April, 2021')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcpDRN4Y1Vem"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "result = pd.DataFrame(columns=['room_type','month','neighbourhood','count','monthly_average'])\n",
        "\n",
        "def monthly_average_by_neigh(result, df, room, month):\n",
        "  price_by_neigh_type = df[['neighbourhood', 'price']].groupby(['neighbourhood']).size().reset_index(name='count')\n",
        "  price_by_neigh_type['monthly_average'] = df['price'].groupby(df['neighbourhood']).transform('mean')\n",
        "  price_by_neigh_type.insert(0, 'month', month)\n",
        "  price_by_neigh_type.insert(0, 'room_type', room)\n",
        "  result = pd.concat([result, price_by_neigh_type])\n",
        "  print(result.shape)\n",
        "  return result\n",
        "\n",
        "def monthly_average_by_room_type(result, df, month):\n",
        "  isHotel = df['room_type'] == 'Hotel room'\n",
        "  result = monthly_average_by_neigh(result, df[isHotel],'Hotel Room', month)\n",
        "  isPrivate = df['room_type'] == 'Private room'\n",
        "  result = monthly_average_by_neigh(result, df[isPrivate],'Private Room', month)\n",
        "  isShared = df['room_type'] == 'Shared room'\n",
        "  result = monthly_average_by_neigh(result, df[isShared],'Shared Room', month)\n",
        "  isEntire = df['room_type'] == 'Entire home/apt'\n",
        "  result = monthly_average_by_neigh(result, df[isEntire], 'Entire Home', month)\n",
        "  return result\n",
        "\n",
        "df = pd.read_csv(\"listings.csv\")\n",
        "result = monthly_average_by_room_type(result, df, 'January, 2020')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsShGMXPrnUn"
      },
      "source": [
        "result.to_excel('01 - jan-aug monthly avg.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdjfQ0tzk6Uk"
      },
      "source": [
        "# LinkedIn Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw1tKOO8Tx4d"
      },
      "source": [
        "Step 1. **Keeping first occurence of repeating job postings.**\n",
        "(first date, last date, and today number displayed at the bottom)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdk8ZXHak4zf"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df3 = pd.read_csv(\"finance.csv\")\n",
        "df1 = pd.read_csv(\"food.csv\")\n",
        "df4 = pd.read_csv(\"professional.csv\")\n",
        "df2 = pd.read_csv(\"trade.csv\")\n",
        "\n",
        "#sort by date\n",
        "df1['Date'] = pd.to_datetime(df1.Date)\n",
        "df1 = df1.sort_values(by='Date')\n",
        "\n",
        "df2['Date'] = pd.to_datetime(df2.Date)\n",
        "df2 = df2.sort_values(by='Date')\n",
        "\n",
        "df3['Date'] = pd.to_datetime(df3.Date)\n",
        "df3 = df3.sort_values(by='Date')\n",
        "\n",
        "df4['Date'] = pd.to_datetime(df4.Date)\n",
        "df4 = df4.sort_values(by='Date')\n",
        "\n",
        "#drop duplicates. keeping the first appearance\n",
        "df1 = df1.drop_duplicates()\n",
        "df2 = df2.drop_duplicates()\n",
        "df3 = df3.drop_duplicates()\n",
        "df4 = df4.drop_duplicates()\n",
        "\n",
        "frames = [df1, df2, df3, df4]\n",
        "result = pd.concat(frames)\n",
        "\n",
        "# Keeping dates starting from November 1st.\n",
        "result = result[(result['Date'] > '2020-10-31')]\n",
        "result = result.sort_values(by='Date')\n",
        "\n",
        "#display results\n",
        "print(\"Start date of data collection:\")\n",
        "print(result.Date.head(1))\n",
        "print(\"Last date of data collection:\")\n",
        "print(result.Date.tail(1))\n",
        "print(\"Size of data:\")\n",
        "print(result.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjjQVhrD3hG_"
      },
      "source": [
        "MANUAL CLEANING STARTS HERE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5hupyStR_XR"
      },
      "source": [
        "######################################\n",
        "########## STEP 1. FEED IN COMBINED DATA FROM PREVIOUS MONTH\n",
        "import pandas as pd\n",
        "\n",
        "result = pd.read_csv(\"COMBINED_NOV_2_APR.csv\")\n",
        "result['Date'] = pd.to_datetime(result.Date)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxYic5-CkKPO"
      },
      "source": [
        "######################################\n",
        "########## STEP 2. FEED IN NEWLY COLLECTED DATA\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df3 = pd.read_csv(\"finance.csv\")\n",
        "df1 = pd.read_csv(\"food.csv\")\n",
        "df4 = pd.read_csv(\"professional.csv\")\n",
        "df2 = pd.read_csv(\"trade.csv\")\n",
        "\n",
        "#sort by date\n",
        "df1['Date'] = pd.to_datetime(df1.Date)\n",
        "df1 = df1.sort_values(by='Date')\n",
        "\n",
        "df2['Date'] = pd.to_datetime(df2.Date)\n",
        "df2 = df2.sort_values(by='Date')\n",
        "\n",
        "df3['Date'] = pd.to_datetime(df3.Date)\n",
        "df3 = df3.sort_values(by='Date')\n",
        "\n",
        "df4['Date'] = pd.to_datetime(df4.Date)\n",
        "df4 = df4.sort_values(by='Date')\n",
        "\n",
        "#drop duplicates. keeping the first appearance\n",
        "df1 = df1.drop_duplicates()\n",
        "df2 = df2.drop_duplicates()\n",
        "df3 = df3.drop_duplicates()\n",
        "df4 = df4.drop_duplicates()\n",
        "\n",
        "frames = [result, df1, df2, df3, df4]\n",
        "result2 = pd.concat(frames)\n",
        "\n",
        "# Keeping dates starting from November 1st.\n",
        "result2 = result2[(result2['Date'] > '2020-10-31')]\n",
        "result2 = result2.sort_values(by='Date')\n",
        "\n",
        "#display results\n",
        "print(\"Start date of data collection:\")\n",
        "print(result2.Date.head(1))\n",
        "print(\"Last date of data collection:\")\n",
        "print(result2.Date.tail(1))\n",
        "print(\"Size of data:\")\n",
        "print(result2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcXJUUvpVxBy"
      },
      "source": [
        "Step 2. **Look for duplicates among 4 industries.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b8H3KByokeR"
      },
      "source": [
        "######################################\n",
        "########## STEP 3. REMOVE DUPLICATES\n",
        "\n",
        "print(result2.shape)\n",
        "\n",
        "#filter out jobs with no links\n",
        "notNaN = result2['Link'] == result2['Link']\n",
        "result2 = result2[notNaN]\n",
        "\n",
        "print(result2.shape)\n",
        "\n",
        "#filter by unique entries(keep first occurence. Food -> Retail -> Finance -> Professional)\n",
        "result2 = result2.drop_duplicates()\n",
        "print(result2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaMbcQ13re6R"
      },
      "source": [
        "######################################\n",
        "########## STEP 4. SAVE, DOWNLOAD, AND RENAME FOLLOWING THE NAMING CONVENTION\n",
        "result2.to_csv('Linkedin_' + str(result2.Date.tail(1)) + '.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye-ukz1FkezS"
      },
      "source": [
        "# YELP DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUveEpetQfot"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel(\"TO_rest_May2Nov_cleaned.xlsx\")\n",
        "print(df.shape)\n",
        "\n",
        "duplicateRowsDF = df[df.duplicated()]\n",
        "print(duplicateRowsDF.shape) #no duplicates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZEgPqG0c-Jt"
      },
      "source": [
        "## DUPLICATE PHONE NUMBERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk9sxs_-XRam"
      },
      "source": [
        "duplicateRowsDF = df[df.duplicated(['phone_x'])]\n",
        "\n",
        "notNaN = duplicateRowsDF['phone_x'] == duplicateRowsDF['phone_x']\n",
        "dfNumnotNaN = duplicateRowsDF[notNaN]\n",
        "\n",
        "pd.concat(g for _, g in dfNumnotNaN.groupby(\"phone_x\") if len(g) > 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBUY9-LydKFY"
      },
      "source": [
        "## 9 RESTAURANTS WHO SHARE SAME NUMBER AND ADDRESS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVS-IRNBZDJa"
      },
      "source": [
        "try_address = pd.concat(g for _, g in dfNumnotNaN.groupby(\"phone_x\") if len(g) > 1)\n",
        "duplicateRowsDF = try_address[try_address.duplicated(['location.address1_x'])]\n",
        "\n",
        "pd.concat(g for _, g in dfNumnotNaN.groupby(\"location.address1_x\") if len(g) > 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19hvuh8GaClu"
      },
      "source": [
        "print(duplicateRowsDF.shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}